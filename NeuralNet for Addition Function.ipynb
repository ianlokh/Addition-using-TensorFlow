{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.8\n",
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(keras.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create RHS operand list from 0..99 (y = 0..99 + 0..99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "lst = [(0, second, third, 0, fifth, sixth) for second in range(0,10) for third in range(0,10) for fifth in range(0,10) for sixth in range(0,10)]\n",
    "print(len(lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add operands for 100 (y = 100 + 0..99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "lst2 = [(1, 0, 0, 0, fifth, sixth) for fifth in range(0,10) for sixth in range(0,10)]\n",
    "print(len(lst2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add operands for 100 (y = 0..99 + 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "lst3 = [(0, second, third, 1, 0, 0) for second in range(0,10) for third in range(0,10)]\n",
    "print(len(lst3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10201\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>num1</th>\n",
       "      <th>num2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  num1  num2\n",
       "0  0  0  0  0  0  0     0     0\n",
       "1  0  0  0  0  0  1     0     1\n",
       "2  0  0  0  0  0  2     0     2\n",
       "3  0  0  0  0  0  3     0     3\n",
       "4  0  0  0  0  0  4     0     4"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst.extend(lst2)\n",
    "lst.extend(lst3)\n",
    "lst.append((1,0,0,1,0,0))\n",
    "lst = pd.DataFrame(lst)\n",
    "lst['num1'] = lst.apply(lambda x: (100*x[0]+10*x[1]+x[2]), axis=1)\n",
    "lst['num2'] = lst.apply(lambda x: (100*x[3]+10*x[4]+x[5]), axis=1)\n",
    "print(len(lst))\n",
    "lst.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the result of the operands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lst['result'] = lst.apply(lambda x: (100*x[0]+10*x[1]+x[2]) + (100*x[3]+10*x[4]+x[5]), axis=1)\n",
    "lst = lst.rename(columns=lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>num1</th>\n",
       "      <th>num2</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>50</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>50</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>50</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>50</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>50</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>50</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2250</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2350</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>50</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2450</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>50</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2550</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2650</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>50</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2750</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>50</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2850</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>50</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2950</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>50</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7150</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>50</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7250</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>50</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7350</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>50</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7450</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>50</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7550</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>50</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7650</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>50</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7750</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>50</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7850</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7950</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>50</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8050</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>50</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8150</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>50</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8250</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>50</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8350</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>50</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8450</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>50</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8550</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>50</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8650</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>50</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8750</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>50</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8850</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>50</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8950</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>50</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9050</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>50</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9150</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>50</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9250</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>50</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9350</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>50</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9450</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>50</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9550</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>50</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9650</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>50</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9750</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>50</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9850</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>50</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9950</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>50</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10050</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1  2  3  4  5  num1  num2  result\n",
       "50     0  0  0  0  5  0     0    50      50\n",
       "150    0  0  1  0  5  0     1    50      51\n",
       "250    0  0  2  0  5  0     2    50      52\n",
       "350    0  0  3  0  5  0     3    50      53\n",
       "450    0  0  4  0  5  0     4    50      54\n",
       "550    0  0  5  0  5  0     5    50      55\n",
       "650    0  0  6  0  5  0     6    50      56\n",
       "750    0  0  7  0  5  0     7    50      57\n",
       "850    0  0  8  0  5  0     8    50      58\n",
       "950    0  0  9  0  5  0     9    50      59\n",
       "1050   0  1  0  0  5  0    10    50      60\n",
       "1150   0  1  1  0  5  0    11    50      61\n",
       "1250   0  1  2  0  5  0    12    50      62\n",
       "1350   0  1  3  0  5  0    13    50      63\n",
       "1450   0  1  4  0  5  0    14    50      64\n",
       "1550   0  1  5  0  5  0    15    50      65\n",
       "1650   0  1  6  0  5  0    16    50      66\n",
       "1750   0  1  7  0  5  0    17    50      67\n",
       "1850   0  1  8  0  5  0    18    50      68\n",
       "1950   0  1  9  0  5  0    19    50      69\n",
       "2050   0  2  0  0  5  0    20    50      70\n",
       "2150   0  2  1  0  5  0    21    50      71\n",
       "2250   0  2  2  0  5  0    22    50      72\n",
       "2350   0  2  3  0  5  0    23    50      73\n",
       "2450   0  2  4  0  5  0    24    50      74\n",
       "2550   0  2  5  0  5  0    25    50      75\n",
       "2650   0  2  6  0  5  0    26    50      76\n",
       "2750   0  2  7  0  5  0    27    50      77\n",
       "2850   0  2  8  0  5  0    28    50      78\n",
       "2950   0  2  9  0  5  0    29    50      79\n",
       "...   .. .. .. .. .. ..   ...   ...     ...\n",
       "7150   0  7  1  0  5  0    71    50     121\n",
       "7250   0  7  2  0  5  0    72    50     122\n",
       "7350   0  7  3  0  5  0    73    50     123\n",
       "7450   0  7  4  0  5  0    74    50     124\n",
       "7550   0  7  5  0  5  0    75    50     125\n",
       "7650   0  7  6  0  5  0    76    50     126\n",
       "7750   0  7  7  0  5  0    77    50     127\n",
       "7850   0  7  8  0  5  0    78    50     128\n",
       "7950   0  7  9  0  5  0    79    50     129\n",
       "8050   0  8  0  0  5  0    80    50     130\n",
       "8150   0  8  1  0  5  0    81    50     131\n",
       "8250   0  8  2  0  5  0    82    50     132\n",
       "8350   0  8  3  0  5  0    83    50     133\n",
       "8450   0  8  4  0  5  0    84    50     134\n",
       "8550   0  8  5  0  5  0    85    50     135\n",
       "8650   0  8  6  0  5  0    86    50     136\n",
       "8750   0  8  7  0  5  0    87    50     137\n",
       "8850   0  8  8  0  5  0    88    50     138\n",
       "8950   0  8  9  0  5  0    89    50     139\n",
       "9050   0  9  0  0  5  0    90    50     140\n",
       "9150   0  9  1  0  5  0    91    50     141\n",
       "9250   0  9  2  0  5  0    92    50     142\n",
       "9350   0  9  3  0  5  0    93    50     143\n",
       "9450   0  9  4  0  5  0    94    50     144\n",
       "9550   0  9  5  0  5  0    95    50     145\n",
       "9650   0  9  6  0  5  0    96    50     146\n",
       "9750   0  9  7  0  5  0    97    50     147\n",
       "9850   0  9  8  0  5  0    98    50     148\n",
       "9950   0  9  9  0  5  0    99    50     149\n",
       "10050  1  0  0  0  5  0   100    50     150\n",
       "\n",
       "[101 rows x 9 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst.iloc[500:1000,0:7].head()\n",
    "lst.loc[lst['num2'] == 50]#.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding for the operand columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          0\n",
       "1          0\n",
       "2          0\n",
       "3          0\n",
       "4          3\n",
       "5          3\n",
       "num1       0\n",
       "num2      33\n",
       "result    33\n",
       "Name: 33, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect specific records\n",
    "lst.iloc[33,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2 12 22 27 37\n"
     ]
    }
   ],
   "source": [
    "enc1 = OneHotEncoder()\n",
    "operand = pd.DataFrame(enc1.fit_transform(pd.DataFrame(lst.iloc[:,0:6])).toarray())\n",
    "operand.head()\n",
    "\n",
    "indx = 33\n",
    "\n",
    "operand.iloc[indx,:]\n",
    "print(np.argmax(operand.iloc[indx,0:1]),\n",
    "      np.argmax(operand.iloc[indx,2:11]),\n",
    "      np.argmax(operand.iloc[indx,12:21]),\n",
    "      np.argmax(operand.iloc[indx,22:23]),\n",
    "      np.argmax(operand.iloc[indx,24:33]),\n",
    "      np.argmax(operand.iloc[indx,34:43]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert first number to bit representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10196</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10197</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10198</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10199</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10200</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1  2  3  4  5  6  7\n",
       "10196  0  1  1  0  0  0  0  0\n",
       "10197  0  1  1  0  0  0  0  1\n",
       "10198  0  1  1  0  0  0  1  0\n",
       "10199  0  1  1  0  0  0  1  1\n",
       "10200  0  1  1  0  0  1  0  0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num1 = [[num] for num in lst['num1']]\n",
    "num1 = np.array(num1,dtype=np.uint8)\n",
    "num1bit = np.unpackbits(num1, axis=1)\n",
    "num1bit = pd.DataFrame(num1bit)\n",
    "num1bit.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert second number to bit representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10196</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10197</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10198</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10199</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10200</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1  2  3  4  5  6  7\n",
       "10196  0  1  1  0  0  1  0  0\n",
       "10197  0  1  1  0  0  1  0  0\n",
       "10198  0  1  1  0  0  1  0  0\n",
       "10199  0  1  1  0  0  1  0  0\n",
       "10200  0  1  1  0  0  1  0  0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num2 = [[num] for num in lst['num2']]\n",
    "num2 = np.array(num2,dtype=np.uint8)\n",
    "num2bit = np.unpackbits(num2, axis=1)\n",
    "num2bit = pd.DataFrame(num2bit)\n",
    "num2bit.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding for the result columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enc2 = OneHotEncoder()\n",
    "result = pd.DataFrame(enc2.fit_transform(pd.DataFrame(lst['result'])).toarray())\n",
    "#enc.n_values_\n",
    "#enc.feature_indices_\n",
    "# convert column lables from int to str\n",
    "#result = result.rename(columns=lambda x: str(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge all the dataframes together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "operand = operand.rename(columns=lambda x: \"oper\"+str(x))\n",
    "data = pd.concat([operand,result], axis=1)\n",
    "#data = data.rename(columns=lambda x: str(x))\n",
    "#data = pd.concat([lst,result], axis=1)\n",
    "\n",
    "# Num1 = 50 - 0 7 12 22 24 34\n",
    "# Num2 = 50 - 0 2 12 22 29 34\n",
    "\n",
    "# Num1 = 70 - 0 9 12 22 24 34\n",
    "# Num2 = 70 - 0 2 12 22 31 34\n",
    "\n",
    "# Num1 = 75 - 0 9 17 22 24 34\n",
    "# Num2 = 75 - 0 2 12 22 31 39\n",
    "\n",
    "# Num1 = 27 - 0 4 19 22 24 34\n",
    "# Num2 = 27 - 0 2 12 22 26 41\n",
    "\n",
    "# Num1 = 33 - 0 5 15 22 24 34\n",
    "# Num2 = 33 - 0 2 12 22 27 37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train test split based on random sampling\n",
    "x_train, x_test, y_train, y_test = train_test_split(data.iloc[:,0:44], data.iloc[:,44:], test_size=0.10, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# manual train test split to exclude specific cases for testing\n",
    "\n",
    "# set all records with specific numbers as test records\n",
    "test = data.loc[(\n",
    "                 (((data[\"oper0\"] == 1) & (data[\"oper7\"] == 1) & (data[\"oper12\"] == 1)) |\n",
    "                  ((data[\"oper22\"] == 1) & (data[\"oper29\"] == 1) & (data[\"oper34\"] == 1))\n",
    "                 )\n",
    "                |\n",
    "                 (((data[\"oper0\"] == 1) & (data[\"oper9\"] == 1) & (data[\"oper12\"] == 1)) |\n",
    "                  ((data[\"oper22\"] == 1) & (data[\"oper31\"] == 1) & (data[\"oper34\"] == 1))\n",
    "                 )\n",
    "                |\n",
    "                 (((data[\"oper0\"] == 1) & (data[\"oper9\"] == 1) & (data[\"oper17\"] == 1)) |\n",
    "                  ((data[\"oper22\"] == 1) & (data[\"oper31\"] == 1) & (data[\"oper39\"] == 1))\n",
    "                 )\n",
    "                |\n",
    "                 (((data[\"oper0\"] == 1) & (data[\"oper4\"] == 1) & (data[\"oper19\"] == 1)) |\n",
    "                  ((data[\"oper22\"] == 1) & (data[\"oper26\"] == 1) & (data[\"oper41\"] == 1))\n",
    "                 )\n",
    "                |\n",
    "                 (((data[\"oper0\"] == 1) & (data[\"oper5\"] == 1) & (data[\"oper15\"] == 1)) |\n",
    "                  ((data[\"oper22\"] == 1) & (data[\"oper27\"] == 1) & (data[\"oper37\"] == 1))\n",
    "                 )\n",
    "                )]\n",
    "\n",
    "x_test = test.iloc[:,0:44]\n",
    "y_test = test.iloc[:,44:245]\n",
    "\n",
    "train = data[~data.index.isin(test.index)]\n",
    "\n",
    "x_train = train.iloc[:,0:44]\n",
    "y_train = train.iloc[:,44:245]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9216, 44)\n",
      "(9216, 201)\n",
      "(985, 44)\n",
      "(985, 201)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "#pd.DataFrame(x_train).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9   ...   191  192  193  194  \\\n",
       "0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "1  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "\n",
       "   195  196  197  198  199  200  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_train).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to maxtrix for Keras input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.as_matrix()\n",
    "x_test = x_test.as_matrix()\n",
    "y_train = y_train.as_matrix()\n",
    "y_test = y_test.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual inspection of test data to ensure correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5 0 0 1 0\n"
     ]
    }
   ],
   "source": [
    "indx = 450\n",
    "x_test[indx]\n",
    "print(np.argmax(x_test[indx,0:1]),\n",
    "      np.argmax(x_test[indx,2:11]),\n",
    "      np.argmax(x_test[indx,12:21]),\n",
    "      np.argmax(x_test[indx,22:23]),\n",
    "      np.argmax(x_test[indx,24:33]),\n",
    "      np.argmax(x_test[indx,34:43]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "y_test[indx]\n",
    "print(np.argmax(y_test[indx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up our Network Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Parameters for basic network\n",
    "learning_rate = 0.075\n",
    "training_epochs = 50\n",
    "batch_size = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 44 # data input\n",
    "n_hidden_1 = 600 # 1st layer number of neurons\n",
    "n_hidden_2 = 300 # 2nd layer number of neurons\n",
    "#n_hidden_3 = 400 # 3nd layer number of neurons\n",
    "#n_hidden_4 = 400 # 4nd layer number of neurons\n",
    "#n_hidden_5 = 400 # 5nd layer number of neurons\n",
    "#n_hidden_6 = 400 # 6nd layer number of neurons\n",
    "n_classes = 201 # classes for prediction(0-200)\n",
    "\n",
    "# changing hidden layer 2 from 400 to 300 dropped the accuracy by 0.5%\n",
    "# changing hidden layer 1 from 500 to 600 increased the accuracy by 0.5%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create functional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Inp = Input(shape=(n_input,))\n",
    "x = Dense(n_hidden_1, activation='relu', name = \"Dense_1\")(Inp)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(n_hidden_2, activation='relu', name = \"Dense_2\")(x)\n",
    "x = Dropout(0.2)(x)\n",
    "#x = Dense(n_hidden_3, activation='relu', name = \"Dense_3\")(x)\n",
    "#x = Dropout(0.2)(x)\n",
    "#x = Dense(n_hidden_4, activation='relu', name = \"Dense_4\")(x)\n",
    "#x = Dropout(0.2)(x)\n",
    "#x = Dense(n_hidden_5, activation='relu', name = \"Dense_5\")(x)\n",
    "#x = Dropout(0.2)(x)\n",
    "#x = Dense(n_hidden_6, activation='relu', name = \"Dense_6\")(x)\n",
    "#output = Dense(n_classes, activation='softmax', name = \"Outputlayer\")(x)\n",
    "output = Dense(n_classes, activation='softmax', name = \"Outputlayer\")(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This creates a model that includes our input, 3 dense hidden layers, output layer\n",
    "model = Model(Inp, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 44)                0         \n",
      "_________________________________________________________________\n",
      "Dense_1 (Dense)              (None, 600)               27000     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "Dense_2 (Dense)              (None, 300)               180300    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "Outputlayer (Dense)          (None, 201)               60501     \n",
      "=================================================================\n",
      "Total params: 267,801\n",
      "Trainable params: 267,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='SGD',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# K is for keras backend\n",
    "K.set_value(model.optimizer.lr, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9216 samples, validate on 985 samples\n",
      "Epoch 1/50\n",
      "1s - loss: 5.2370 - acc: 0.0077 - val_loss: 5.0771 - val_acc: 0.0061\n",
      "Epoch 2/50\n",
      "1s - loss: 5.1312 - acc: 0.0080 - val_loss: 4.9878 - val_acc: 0.0102\n",
      "Epoch 3/50\n",
      "1s - loss: 5.0268 - acc: 0.0106 - val_loss: 4.8184 - val_acc: 0.0152\n",
      "Epoch 4/50\n",
      "1s - loss: 4.7738 - acc: 0.0162 - val_loss: 4.4853 - val_acc: 0.0284\n",
      "Epoch 5/50\n",
      "1s - loss: 4.5063 - acc: 0.0278 - val_loss: 4.2384 - val_acc: 0.0325\n",
      "Epoch 6/50\n",
      "1s - loss: 4.3095 - acc: 0.0317 - val_loss: 4.0899 - val_acc: 0.0355\n",
      "Epoch 7/50\n",
      "1s - loss: 4.1735 - acc: 0.0331 - val_loss: 3.9618 - val_acc: 0.0416\n",
      "Epoch 8/50\n",
      "1s - loss: 4.0413 - acc: 0.0416 - val_loss: 3.8594 - val_acc: 0.0508\n",
      "Epoch 9/50\n",
      "1s - loss: 3.9220 - acc: 0.0451 - val_loss: 3.7900 - val_acc: 0.0437\n",
      "Epoch 10/50\n",
      "1s - loss: 3.8352 - acc: 0.0475 - val_loss: 3.7004 - val_acc: 0.0518\n",
      "Epoch 11/50\n",
      "1s - loss: 3.7418 - acc: 0.0515 - val_loss: 3.6201 - val_acc: 0.0599\n",
      "Epoch 12/50\n",
      "1s - loss: 3.6683 - acc: 0.0554 - val_loss: 3.5773 - val_acc: 0.0680\n",
      "Epoch 13/50\n",
      "1s - loss: 3.5864 - acc: 0.0601 - val_loss: 3.5179 - val_acc: 0.0538\n",
      "Epoch 14/50\n",
      "1s - loss: 3.5109 - acc: 0.0673 - val_loss: 3.4320 - val_acc: 0.0680\n",
      "Epoch 15/50\n",
      "1s - loss: 3.4482 - acc: 0.0696 - val_loss: 3.3682 - val_acc: 0.0812\n",
      "Epoch 16/50\n",
      "1s - loss: 3.3692 - acc: 0.0760 - val_loss: 3.3167 - val_acc: 0.0924\n",
      "Epoch 17/50\n",
      "1s - loss: 3.2930 - acc: 0.0860 - val_loss: 3.2669 - val_acc: 0.0822\n",
      "Epoch 18/50\n",
      "1s - loss: 3.2071 - acc: 0.1060 - val_loss: 3.1403 - val_acc: 0.0995\n",
      "Epoch 19/50\n",
      "1s - loss: 3.0696 - acc: 0.1259 - val_loss: 2.9437 - val_acc: 0.1685\n",
      "Epoch 20/50\n",
      "1s - loss: 2.8797 - acc: 0.1645 - val_loss: 2.7131 - val_acc: 0.1888\n",
      "Epoch 21/50\n",
      "1s - loss: 2.6641 - acc: 0.2024 - val_loss: 2.4878 - val_acc: 0.2447\n",
      "Epoch 22/50\n",
      "1s - loss: 2.4782 - acc: 0.2401 - val_loss: 2.3106 - val_acc: 0.2914\n",
      "Epoch 23/50\n",
      "1s - loss: 2.2974 - acc: 0.3028 - val_loss: 2.0655 - val_acc: 0.4335\n",
      "Epoch 24/50\n",
      "1s - loss: 2.0282 - acc: 0.3996 - val_loss: 1.8279 - val_acc: 0.5147\n",
      "Epoch 25/50\n",
      "1s - loss: 1.7359 - acc: 0.5005 - val_loss: 1.4638 - val_acc: 0.6954\n",
      "Epoch 26/50\n",
      "1s - loss: 1.4197 - acc: 0.6102 - val_loss: 1.1349 - val_acc: 0.7970\n",
      "Epoch 27/50\n",
      "1s - loss: 1.1587 - acc: 0.6915 - val_loss: 0.8468 - val_acc: 0.8629\n",
      "Epoch 28/50\n",
      "1s - loss: 0.9521 - acc: 0.7477 - val_loss: 0.6456 - val_acc: 0.9259\n",
      "Epoch 29/50\n",
      "1s - loss: 0.8098 - acc: 0.7872 - val_loss: 0.5227 - val_acc: 0.9431\n",
      "Epoch 30/50\n",
      "1s - loss: 0.6878 - acc: 0.8231 - val_loss: 0.4314 - val_acc: 0.9655\n",
      "Epoch 31/50\n",
      "1s - loss: 0.6060 - acc: 0.8406 - val_loss: 0.3914 - val_acc: 0.9411\n",
      "Epoch 32/50\n",
      "1s - loss: 0.5374 - acc: 0.8637 - val_loss: 0.3258 - val_acc: 0.9624\n",
      "Epoch 33/50\n",
      "1s - loss: 0.4713 - acc: 0.8789 - val_loss: 0.2846 - val_acc: 0.9777\n",
      "Epoch 34/50\n",
      "1s - loss: 0.4317 - acc: 0.8887 - val_loss: 0.2615 - val_acc: 0.9614\n",
      "Epoch 35/50\n",
      "1s - loss: 0.3916 - acc: 0.9032 - val_loss: 0.2340 - val_acc: 0.9645\n",
      "Epoch 36/50\n",
      "1s - loss: 0.3561 - acc: 0.9096 - val_loss: 0.1988 - val_acc: 0.9787\n",
      "Epoch 37/50\n",
      "1s - loss: 0.3177 - acc: 0.9277 - val_loss: 0.1826 - val_acc: 0.9817\n",
      "Epoch 38/50\n",
      "1s - loss: 0.2910 - acc: 0.9326 - val_loss: 0.1757 - val_acc: 0.9807\n",
      "Epoch 39/50\n",
      "1s - loss: 0.2678 - acc: 0.9385 - val_loss: 0.1440 - val_acc: 0.9807\n",
      "Epoch 40/50\n",
      "1s - loss: 0.2509 - acc: 0.9413 - val_loss: 0.1309 - val_acc: 0.9797\n",
      "Epoch 41/50\n",
      "1s - loss: 0.2298 - acc: 0.9463 - val_loss: 0.1275 - val_acc: 0.9838\n",
      "Epoch 42/50\n",
      "1s - loss: 0.2176 - acc: 0.9491 - val_loss: 0.1226 - val_acc: 0.9807\n",
      "Epoch 43/50\n",
      "1s - loss: 0.2023 - acc: 0.9549 - val_loss: 0.1034 - val_acc: 0.9888\n",
      "Epoch 44/50\n",
      "1s - loss: 0.1881 - acc: 0.9569 - val_loss: 0.0952 - val_acc: 0.9898\n",
      "Epoch 45/50\n",
      "1s - loss: 0.1796 - acc: 0.9571 - val_loss: 0.0862 - val_acc: 0.9878\n",
      "Epoch 46/50\n",
      "1s - loss: 0.1671 - acc: 0.9642 - val_loss: 0.0835 - val_acc: 0.9868\n",
      "Epoch 47/50\n",
      "1s - loss: 0.1545 - acc: 0.9673 - val_loss: 0.0808 - val_acc: 0.9868\n",
      "Epoch 48/50\n",
      "1s - loss: 0.1461 - acc: 0.9695 - val_loss: 0.0745 - val_acc: 0.9878\n",
      "Epoch 49/50\n",
      "1s - loss: 0.1382 - acc: 0.9727 - val_loss: 0.0667 - val_acc: 0.9929\n",
      "Epoch 50/50\n",
      "1s - loss: 0.1305 - acc: 0.9736 - val_loss: 0.0659 - val_acc: 0.9909\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=training_epochs,\n",
    "                    verbose=2, # This is for what we want it to display out as it trains \n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_train(hist):\n",
    "    h = hist.history\n",
    "    if 'acc' in h:\n",
    "        meas='acc'\n",
    "        loc='lower right'\n",
    "    else:\n",
    "        meas='loss'\n",
    "        loc='upper right'\n",
    "    plt.plot(hist.history[meas])\n",
    "    plt.plot(hist.history['val_'+meas])\n",
    "    plt.title('model '+meas)\n",
    "    plt.ylabel(meas)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc=loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1337a6668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_train(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 8 0 7 5\n"
     ]
    }
   ],
   "source": [
    "indx = 44\n",
    "\n",
    "print(np.argmax(x_test[indx,0:1]),\n",
    "      np.argmax(x_test[indx,2:11]),\n",
    "      np.argmax(x_test[indx,12:21]),\n",
    "      np.argmax(x_test[indx,22:23]),\n",
    "      np.argmax(x_test[indx,24:33]),\n",
    "      np.argmax(x_test[indx,34:43]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n"
     ]
    }
   ],
   "source": [
    "for result in model.predict(x_test[indx:indx+1]):\n",
    "    print(np.argmax(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.163247558066\n",
      "Test accuracy: 0.96548223326\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_test = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         0\n",
      "          1       1.00      1.00      1.00         2\n",
      "          2       1.00      1.00      1.00         2\n",
      "          3       1.00      1.00      1.00         2\n",
      "          4       1.00      1.00      1.00         2\n",
      "          5       1.00      1.00      1.00         2\n",
      "          6       1.00      1.00      1.00         2\n",
      "          7       1.00      0.25      0.40         4\n",
      "          8       1.00      1.00      1.00         4\n",
      "          9       1.00      1.00      1.00         4\n",
      "         10       1.00      1.00      1.00         4\n",
      "         11       1.00      1.00      1.00         4\n",
      "         12       1.00      1.00      1.00         4\n",
      "         13       1.00      1.00      1.00         4\n",
      "         14       1.00      1.00      1.00         4\n",
      "         15       1.00      1.00      1.00         4\n",
      "         16       1.00      1.00      1.00         4\n",
      "         17       1.00      1.00      1.00         4\n",
      "         18       1.00      1.00      1.00         4\n",
      "         19       0.67      1.00      0.80         4\n",
      "         20       1.00      1.00      1.00         4\n",
      "         21       1.00      1.00      1.00         4\n",
      "         22       1.00      1.00      1.00         4\n",
      "         23       1.00      1.00      1.00         4\n",
      "         24       1.00      0.67      0.80         6\n",
      "         25       1.00      0.83      0.91         6\n",
      "         26       1.00      1.00      1.00         6\n",
      "         27       1.00      1.00      1.00         6\n",
      "         28       1.00      1.00      1.00         5\n",
      "         29       1.00      0.67      0.80         6\n",
      "         30       1.00      1.00      1.00         6\n",
      "         31       1.00      1.00      1.00         6\n",
      "         32       1.00      1.00      1.00         6\n",
      "         33       1.00      1.00      1.00         6\n",
      "         34       0.67      1.00      0.80         4\n",
      "         35       0.86      1.00      0.92         6\n",
      "         36       1.00      1.00      1.00         6\n",
      "         37       1.00      1.00      1.00         6\n",
      "         38       1.00      1.00      1.00         6\n",
      "         39       1.00      1.00      1.00         6\n",
      "         40       1.00      1.00      1.00         5\n",
      "         41       1.00      1.00      1.00         6\n",
      "         42       1.00      1.00      1.00         6\n",
      "         43       1.00      1.00      1.00         6\n",
      "         44       1.00      0.75      0.86         8\n",
      "         45       1.00      1.00      1.00         8\n",
      "         46       1.00      0.88      0.93         8\n",
      "         47       0.00      0.00      0.00         8\n",
      "         48       1.00      1.00      1.00         8\n",
      "         49       1.00      1.00      1.00        10\n",
      "         50       1.00      1.00      1.00        10\n",
      "         51       1.00      1.00      1.00         8\n",
      "         52       1.00      1.00      1.00        10\n",
      "         53       1.00      1.00      1.00        10\n",
      "         54       0.83      1.00      0.91        10\n",
      "         55       1.00      1.00      1.00        10\n",
      "         56       0.91      1.00      0.95        10\n",
      "         57       0.50      1.00      0.67         8\n",
      "         58       1.00      1.00      1.00        10\n",
      "         59       1.00      1.00      1.00        10\n",
      "         60       1.00      1.00      1.00        10\n",
      "         61       1.00      1.00      1.00        10\n",
      "         62       1.00      1.00      1.00        10\n",
      "         63       1.00      1.00      1.00        10\n",
      "         64       1.00      1.00      1.00        10\n",
      "         65       1.00      1.00      1.00        10\n",
      "         66       1.00      1.00      1.00        10\n",
      "         67       1.00      1.00      1.00        10\n",
      "         68       1.00      1.00      1.00        10\n",
      "         69       1.00      1.00      1.00        10\n",
      "         70       1.00      1.00      1.00        10\n",
      "         71       1.00      1.00      1.00         8\n",
      "         72       1.00      1.00      1.00        10\n",
      "         73       1.00      1.00      1.00        10\n",
      "         74       1.00      1.00      1.00         9\n",
      "         75       1.00      1.00      1.00        10\n",
      "         76       1.00      1.00      1.00         8\n",
      "         77       1.00      1.00      1.00         8\n",
      "         78       1.00      1.00      1.00        10\n",
      "         79       1.00      1.00      1.00        10\n",
      "         80       1.00      1.00      1.00        10\n",
      "         81       1.00      1.00      1.00        10\n",
      "         82       1.00      1.00      1.00         8\n",
      "         83       1.00      1.00      1.00        10\n",
      "         84       1.00      1.00      1.00        10\n",
      "         85       1.00      1.00      1.00        10\n",
      "         86       1.00      1.00      1.00        10\n",
      "         87       1.00      1.00      1.00        10\n",
      "         88       1.00      1.00      1.00        10\n",
      "         89       1.00      1.00      1.00        10\n",
      "         90       1.00      1.00      1.00        10\n",
      "         91       0.83      1.00      0.91        10\n",
      "         92       1.00      1.00      1.00        10\n",
      "         93       1.00      1.00      1.00        10\n",
      "         94       1.00      1.00      1.00         8\n",
      "         95       1.00      1.00      1.00        10\n",
      "         96       1.00      1.00      1.00        10\n",
      "         97       1.00      1.00      1.00        10\n",
      "         98       1.00      1.00      1.00        10\n",
      "         99       1.00      1.00      1.00         8\n",
      "        100       1.00      1.00      1.00        10\n",
      "        101       1.00      0.80      0.89        10\n",
      "        102       1.00      1.00      1.00         8\n",
      "        103       1.00      1.00      1.00         8\n",
      "        104       1.00      0.75      0.86         8\n",
      "        105       1.00      0.88      0.93         8\n",
      "        106       1.00      1.00      1.00         8\n",
      "        107       1.00      1.00      1.00         8\n",
      "        108       1.00      1.00      1.00         6\n",
      "        109       1.00      1.00      1.00         6\n",
      "        110       1.00      1.00      1.00         6\n",
      "        111       1.00      1.00      1.00         6\n",
      "        112       1.00      1.00      1.00         6\n",
      "        113       1.00      1.00      1.00         6\n",
      "        114       0.71      1.00      0.83         5\n",
      "        115       0.80      0.67      0.73         6\n",
      "        116       1.00      0.67      0.80         6\n",
      "        117       1.00      1.00      1.00         6\n",
      "        118       1.00      1.00      1.00         6\n",
      "        119       1.00      1.00      1.00         4\n",
      "        120       1.00      1.00      1.00         6\n",
      "        121       1.00      1.00      1.00         6\n",
      "        122       1.00      1.00      1.00         6\n",
      "        123       1.00      1.00      1.00         6\n",
      "        124       1.00      0.60      0.75         5\n",
      "        125       0.67      1.00      0.80         4\n",
      "        126       0.67      1.00      0.80         4\n",
      "        127       1.00      1.00      1.00         4\n",
      "        128       1.00      1.00      1.00         4\n",
      "        129       1.00      1.00      1.00         4\n",
      "        130       1.00      1.00      1.00         4\n",
      "        131       1.00      1.00      1.00         4\n",
      "        132       1.00      1.00      1.00         4\n",
      "        133       1.00      1.00      1.00         4\n",
      "        134       0.50      1.00      0.67         4\n",
      "        135       1.00      1.00      1.00         4\n",
      "        136       1.00      1.00      1.00         4\n",
      "        137       1.00      1.00      1.00         4\n",
      "        138       1.00      1.00      1.00         4\n",
      "        139       0.67      1.00      0.80         4\n",
      "        140       1.00      1.00      1.00         4\n",
      "        141       1.00      1.00      1.00         4\n",
      "        142       1.00      1.00      1.00         4\n",
      "        143       1.00      1.00      1.00         4\n",
      "        144       1.00      0.50      0.67         4\n",
      "        145       1.00      1.00      1.00         2\n",
      "        146       1.00      1.00      1.00         2\n",
      "        147       1.00      1.00      1.00         2\n",
      "        148       1.00      1.00      1.00         2\n",
      "        149       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.97      0.97      0.96       985\n",
      "\n",
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 2 0 ..., 0 0 0]\n",
      " [0 0 2 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 2 0 0]\n",
      " [0 0 0 ..., 0 2 0]\n",
      " [0 0 0 ..., 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ianlo/anaconda/envs/tensorflow13_py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 150, does not match size of target_names, 200\n",
      "  .format(len(labels), len(target_names))\n",
      "/Users/ianlo/anaconda/envs/tensorflow13_py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/ianlo/anaconda/envs/tensorflow13_py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "target_names = [str(cls) for cls in range(0,y_train.shape[1]-1)]\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASkAAAD3CAYAAABB2qJpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12b85e940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "confmat=confusion_matrix(y_test, y_pred)\n",
    "ticks=np.linspace(0, 200,num=201)\n",
    "plt.imshow(confmat, interpolation='none')\n",
    "plt.colorbar()\n",
    "plt.xticks(ticks,fontsize=6)\n",
    "plt.yticks(ticks,fontsize=6)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
