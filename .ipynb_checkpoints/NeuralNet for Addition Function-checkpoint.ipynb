{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.4\n",
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(keras.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create RHS operand list from 0..99 (y = 0..99 + 0..99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "lst = [(0, second, third, 0, fifth, sixth) for second in range(0,10) for third in range(0,10) for fifth in range(0,10) for sixth in range(0,10)]\n",
    "print(len(lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add operands for 100 (y = 100 + 0..99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "lst2 = [(1, 0, 0, 0, fifth, sixth) for fifth in range(0,10) for sixth in range(0,10)]\n",
    "print(len(lst2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add operands for 100 (y = 0..99 + 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "lst3 = [(0, second, third, 1, 0, 0) for second in range(0,10) for third in range(0,10)]\n",
    "print(len(lst3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10201\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>num1</th>\n",
       "      <th>num2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  num1  num2\n",
       "0  0  0  0  0  0  0     0     0\n",
       "1  0  0  0  0  0  1     0     1\n",
       "2  0  0  0  0  0  2     0     2\n",
       "3  0  0  0  0  0  3     0     3\n",
       "4  0  0  0  0  0  4     0     4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst.extend(lst2)\n",
    "lst.extend(lst3)\n",
    "lst.append((1,0,0,1,0,0))\n",
    "lst = pd.DataFrame(lst)\n",
    "lst['num1'] = lst.apply(lambda x: (100*x[0]+10*x[1]+x[2]), axis=1)\n",
    "lst['num2'] = lst.apply(lambda x: (100*x[3]+10*x[4]+x[5]), axis=1)\n",
    "print(len(lst))\n",
    "lst.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the result of the operands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lst['result'] = lst.apply(lambda x: (100*x[0]+10*x[1]+x[2]) + (100*x[3]+10*x[4]+x[5]), axis=1)\n",
    "lst = lst.rename(columns=lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>num1</th>\n",
       "      <th>num2</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>50</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>50</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>50</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>50</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>50</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>50</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2250</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2350</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>50</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2450</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>50</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2550</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2650</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>50</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2750</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>50</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2850</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>50</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2950</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>50</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7150</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>50</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7250</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>50</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7350</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>50</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7450</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>50</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7550</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>50</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7650</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>50</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7750</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>50</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7850</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7950</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>50</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8050</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>50</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8150</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>50</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8250</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>50</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8350</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>50</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8450</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>50</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8550</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>50</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8650</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>50</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8750</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>50</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8850</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>50</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8950</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>50</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9050</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>50</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9150</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>50</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9250</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>50</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9350</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>50</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9450</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>50</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9550</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>50</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9650</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>50</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9750</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>50</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9850</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>50</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9950</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>50</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10050</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1  2  3  4  5  num1  num2  result\n",
       "50     0  0  0  0  5  0     0    50      50\n",
       "150    0  0  1  0  5  0     1    50      51\n",
       "250    0  0  2  0  5  0     2    50      52\n",
       "350    0  0  3  0  5  0     3    50      53\n",
       "450    0  0  4  0  5  0     4    50      54\n",
       "550    0  0  5  0  5  0     5    50      55\n",
       "650    0  0  6  0  5  0     6    50      56\n",
       "750    0  0  7  0  5  0     7    50      57\n",
       "850    0  0  8  0  5  0     8    50      58\n",
       "950    0  0  9  0  5  0     9    50      59\n",
       "1050   0  1  0  0  5  0    10    50      60\n",
       "1150   0  1  1  0  5  0    11    50      61\n",
       "1250   0  1  2  0  5  0    12    50      62\n",
       "1350   0  1  3  0  5  0    13    50      63\n",
       "1450   0  1  4  0  5  0    14    50      64\n",
       "1550   0  1  5  0  5  0    15    50      65\n",
       "1650   0  1  6  0  5  0    16    50      66\n",
       "1750   0  1  7  0  5  0    17    50      67\n",
       "1850   0  1  8  0  5  0    18    50      68\n",
       "1950   0  1  9  0  5  0    19    50      69\n",
       "2050   0  2  0  0  5  0    20    50      70\n",
       "2150   0  2  1  0  5  0    21    50      71\n",
       "2250   0  2  2  0  5  0    22    50      72\n",
       "2350   0  2  3  0  5  0    23    50      73\n",
       "2450   0  2  4  0  5  0    24    50      74\n",
       "2550   0  2  5  0  5  0    25    50      75\n",
       "2650   0  2  6  0  5  0    26    50      76\n",
       "2750   0  2  7  0  5  0    27    50      77\n",
       "2850   0  2  8  0  5  0    28    50      78\n",
       "2950   0  2  9  0  5  0    29    50      79\n",
       "...   .. .. .. .. .. ..   ...   ...     ...\n",
       "7150   0  7  1  0  5  0    71    50     121\n",
       "7250   0  7  2  0  5  0    72    50     122\n",
       "7350   0  7  3  0  5  0    73    50     123\n",
       "7450   0  7  4  0  5  0    74    50     124\n",
       "7550   0  7  5  0  5  0    75    50     125\n",
       "7650   0  7  6  0  5  0    76    50     126\n",
       "7750   0  7  7  0  5  0    77    50     127\n",
       "7850   0  7  8  0  5  0    78    50     128\n",
       "7950   0  7  9  0  5  0    79    50     129\n",
       "8050   0  8  0  0  5  0    80    50     130\n",
       "8150   0  8  1  0  5  0    81    50     131\n",
       "8250   0  8  2  0  5  0    82    50     132\n",
       "8350   0  8  3  0  5  0    83    50     133\n",
       "8450   0  8  4  0  5  0    84    50     134\n",
       "8550   0  8  5  0  5  0    85    50     135\n",
       "8650   0  8  6  0  5  0    86    50     136\n",
       "8750   0  8  7  0  5  0    87    50     137\n",
       "8850   0  8  8  0  5  0    88    50     138\n",
       "8950   0  8  9  0  5  0    89    50     139\n",
       "9050   0  9  0  0  5  0    90    50     140\n",
       "9150   0  9  1  0  5  0    91    50     141\n",
       "9250   0  9  2  0  5  0    92    50     142\n",
       "9350   0  9  3  0  5  0    93    50     143\n",
       "9450   0  9  4  0  5  0    94    50     144\n",
       "9550   0  9  5  0  5  0    95    50     145\n",
       "9650   0  9  6  0  5  0    96    50     146\n",
       "9750   0  9  7  0  5  0    97    50     147\n",
       "9850   0  9  8  0  5  0    98    50     148\n",
       "9950   0  9  9  0  5  0    99    50     149\n",
       "10050  1  0  0  0  5  0   100    50     150\n",
       "\n",
       "[101 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst.iloc[500:1000,0:7].head()\n",
    "lst.loc[lst['num2'] == 50]#.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding for the operand columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          0\n",
       "1          0\n",
       "2          0\n",
       "3          0\n",
       "4          5\n",
       "5          0\n",
       "num1       0\n",
       "num2      50\n",
       "result    50\n",
       "Name: 50, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect specific records\n",
    "lst.iloc[50,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2 12 22 29 34\n"
     ]
    }
   ],
   "source": [
    "enc1 = OneHotEncoder()\n",
    "operand = pd.DataFrame(enc1.fit_transform(pd.DataFrame(lst.iloc[:,0:6])).toarray())\n",
    "operand.head()\n",
    "\n",
    "indx = 50\n",
    "\n",
    "operand.iloc[indx,:]\n",
    "print(np.argmax(operand.iloc[indx,0:1]),\n",
    "      np.argmax(operand.iloc[indx,2:11]),\n",
    "      np.argmax(operand.iloc[indx,12:21]),\n",
    "      np.argmax(operand.iloc[indx,22:23]),\n",
    "      np.argmax(operand.iloc[indx,24:33]),\n",
    "      np.argmax(operand.iloc[indx,34:43]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert first number to bit representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10196</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10197</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10198</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10199</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10200</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1  2  3  4  5  6  7\n",
       "10196  0  1  1  0  0  0  0  0\n",
       "10197  0  1  1  0  0  0  0  1\n",
       "10198  0  1  1  0  0  0  1  0\n",
       "10199  0  1  1  0  0  0  1  1\n",
       "10200  0  1  1  0  0  1  0  0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num1 = [[num] for num in lst['num1']]\n",
    "num1 = np.array(num1,dtype=np.uint8)\n",
    "num1bit = np.unpackbits(num1, axis=1)\n",
    "num1bit = pd.DataFrame(num1bit)\n",
    "num1bit.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert second number to bit representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10196</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10197</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10198</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10199</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10200</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1  2  3  4  5  6  7\n",
       "10196  0  1  1  0  0  1  0  0\n",
       "10197  0  1  1  0  0  1  0  0\n",
       "10198  0  1  1  0  0  1  0  0\n",
       "10199  0  1  1  0  0  1  0  0\n",
       "10200  0  1  1  0  0  1  0  0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num2 = [[num] for num in lst['num2']]\n",
    "num2 = np.array(num2,dtype=np.uint8)\n",
    "num2bit = np.unpackbits(num2, axis=1)\n",
    "num2bit = pd.DataFrame(num2bit)\n",
    "num2bit.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding for the result columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enc2 = OneHotEncoder()\n",
    "result = pd.DataFrame(enc2.fit_transform(pd.DataFrame(lst['result'])).toarray())\n",
    "#enc.n_values_\n",
    "#enc.feature_indices_\n",
    "# convert column lables from int to str\n",
    "#result = result.rename(columns=lambda x: str(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge all the dataframes together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "operand = operand.rename(columns=lambda x: \"oper\"+str(x))\n",
    "data = pd.concat([operand,result], axis=1)\n",
    "#data = data.rename(columns=lambda x: str(x))\n",
    "#data = pd.concat([lst,result], axis=1)\n",
    "\n",
    "# Num1 = 50 - 0 7 12 22 24 34\n",
    "# Num2 = 50 - 0 2 12 22 29 34\n",
    "\n",
    "# Num1 = 70 - 0 9 12 22 24 34\n",
    "# Num2 = 70 - 0 2 12 22 31 34\n",
    "\n",
    "# Num1 = 75 - 0 9 17 22 24 34\n",
    "# Num2 = 75 - 0 2 12 22 31 39\n",
    "\n",
    "# Num1 = 27 - 0 4 19 22 24 34\n",
    "# Num2 = 27 - 0 2 12 22 26 41\n",
    "\n",
    "# Num1 = 33 - 0 5 15 22 24 34\n",
    "# Num2 = 33 - 0 2 12 22 27 37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train test split based on random sampling\n",
    "x_train, x_test, y_train, y_test = train_test_split(data.iloc[:,0:44], data.iloc[:,44:], test_size=0.10, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual train test split to exclude specific cases for testing\n",
    "\n",
    "# set all records with specific numbers as test records\n",
    "test = data.loc[(\n",
    "                 (((data[\"oper0\"] == 1) & (data[\"oper7\"] == 1) & (data[\"oper12\"] == 1)) |\n",
    "#                  ((data[\"oper22\"] == 1) & (data[\"oper29\"] == 1) & (data[\"oper34\"] == 1))\n",
    "                  ((data[\"oper22\"] == 1) & (data[\"oper29\"] == 1))\n",
    "                 )\n",
    "                |\n",
    "                 (((data[\"oper0\"] == 1) & (data[\"oper9\"] == 1) & (data[\"oper12\"] == 1)) |\n",
    "                  ((data[\"oper22\"] == 1) & (data[\"oper31\"] == 1) & (data[\"oper34\"] == 1))\n",
    "                 )\n",
    "                |\n",
    "                 (((data[\"oper0\"] == 1) & (data[\"oper9\"] == 1) & (data[\"oper17\"] == 1)) |\n",
    "                  ((data[\"oper22\"] == 1) & (data[\"oper31\"] == 1) & (data[\"oper39\"] == 1))\n",
    "                 )\n",
    "                |\n",
    "                 (((data[\"oper0\"] == 1) & (data[\"oper4\"] == 1) & (data[\"oper19\"] == 1)) |\n",
    "                  ((data[\"oper22\"] == 1) & (data[\"oper26\"] == 1) & (data[\"oper41\"] == 1))\n",
    "                 )\n",
    "                |\n",
    "                 (((data[\"oper0\"] == 1) & (data[\"oper5\"] == 1) & (data[\"oper15\"] == 1)) |\n",
    "                  ((data[\"oper22\"] == 1) & (data[\"oper27\"] == 1) & (data[\"oper37\"] == 1))\n",
    "                 )\n",
    "                )]\n",
    "\n",
    "x_test = test.iloc[:,0:44]\n",
    "y_test = test.iloc[:,44:245]\n",
    "\n",
    "train = data[~data.index.isin(test.index)]\n",
    "\n",
    "x_train = train.iloc[:,0:44]\n",
    "y_train = train.iloc[:,44:245]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8352, 44)\n",
      "(8352, 201)\n",
      "(1849, 44)\n",
      "(1849, 201)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "#pd.DataFrame(x_train).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9   ...   191  192  193  194  \\\n",
       "0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "1  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "\n",
       "   195  196  197  198  199  200  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_train).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to maxtrix for Keras input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.as_matrix()\n",
    "x_test = x_test.as_matrix()\n",
    "y_train = y_train.as_matrix()\n",
    "y_test = y_test.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual inspection of test data to ensure correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2 7 0 7 2\n"
     ]
    }
   ],
   "source": [
    "indx = 450\n",
    "x_test[indx]\n",
    "print(np.argmax(x_test[indx,0:1]),\n",
    "      np.argmax(x_test[indx,2:11]),\n",
    "      np.argmax(x_test[indx,12:21]),\n",
    "      np.argmax(x_test[indx,22:23]),\n",
    "      np.argmax(x_test[indx,24:33]),\n",
    "      np.argmax(x_test[indx,34:43]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "y_test[indx]\n",
    "print(np.argmax(y_test[indx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up our Network Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Parameters for basic network\n",
    "learning_rate = 0.1\n",
    "training_epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 44 # data input\n",
    "n_hidden_1 = 600 # 1st layer number of neurons\n",
    "n_hidden_2 = 300 # 2nd layer number of neurons\n",
    "#n_hidden_3 = 400 # 3nd layer number of neurons\n",
    "#n_hidden_4 = 400 # 4nd layer number of neurons\n",
    "#n_hidden_5 = 400 # 5nd layer number of neurons\n",
    "#n_hidden_6 = 400 # 6nd layer number of neurons\n",
    "n_classes = 201 # classes for prediction(0-200)\n",
    "\n",
    "# changing hidden layer 2 from 400 to 300 dropped the accuracy by 0.5%\n",
    "# changing hidden layer 1 from 500 to 600 increased the accuracy by 0.5%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create functional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Inp = Input(shape=(n_input,))\n",
    "x = Dense(n_hidden_1, activation='relu', name = \"Dense_1\")(Inp)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(n_hidden_2, activation='relu', name = \"Dense_2\")(x)\n",
    "x = Dropout(0.2)(x)\n",
    "#x = Dense(n_hidden_3, activation='relu', name = \"Dense_3\")(x)\n",
    "#x = Dropout(0.2)(x)\n",
    "#x = Dense(n_hidden_4, activation='relu', name = \"Dense_4\")(x)\n",
    "#x = Dropout(0.2)(x)\n",
    "#x = Dense(n_hidden_5, activation='relu', name = \"Dense_5\")(x)\n",
    "#x = Dropout(0.2)(x)\n",
    "#x = Dense(n_hidden_6, activation='relu', name = \"Dense_6\")(x)\n",
    "#output = Dense(n_classes, activation='softmax', name = \"Outputlayer\")(x)\n",
    "output = Dense(n_classes, activation='softmax', name = \"Outputlayer\")(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This creates a model that includes our input, 3 dense hidden layers, output layer\n",
    "model = Model(Inp, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 44)                0         \n",
      "_________________________________________________________________\n",
      "Dense_1 (Dense)              (None, 600)               27000     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "Dense_2 (Dense)              (None, 300)               180300    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "Outputlayer (Dense)          (None, 201)               60501     \n",
      "=================================================================\n",
      "Total params: 267,801\n",
      "Trainable params: 267,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='SGD',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# K is for keras backend\n",
    "K.set_value(model.optimizer.lr, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8352 samples, validate on 1849 samples\n",
      "Epoch 1/50\n",
      "1s - loss: 5.2631 - acc: 0.0073 - val_loss: 5.1406 - val_acc: 0.0119\n",
      "Epoch 2/50\n",
      "1s - loss: 5.1633 - acc: 0.0077 - val_loss: 5.0214 - val_acc: 0.0081\n",
      "Epoch 3/50\n",
      "1s - loss: 5.0913 - acc: 0.0102 - val_loss: 4.9406 - val_acc: 0.0087\n",
      "Epoch 4/50\n",
      "1s - loss: 4.9255 - acc: 0.0120 - val_loss: 4.7057 - val_acc: 0.0195\n",
      "Epoch 5/50\n",
      "1s - loss: 4.6491 - acc: 0.0213 - val_loss: 4.4684 - val_acc: 0.0189\n",
      "Epoch 6/50\n",
      "1s - loss: 4.4210 - acc: 0.0263 - val_loss: 4.3372 - val_acc: 0.0265\n",
      "Epoch 7/50\n",
      "1s - loss: 4.2574 - acc: 0.0310 - val_loss: 4.2795 - val_acc: 0.0227\n",
      "Epoch 8/50\n",
      "1s - loss: 4.1079 - acc: 0.0357 - val_loss: 4.2334 - val_acc: 0.0211\n",
      "Epoch 9/50\n",
      "1s - loss: 3.9982 - acc: 0.0387 - val_loss: 4.1918 - val_acc: 0.0206\n",
      "Epoch 10/50\n",
      "1s - loss: 3.8888 - acc: 0.0433 - val_loss: 4.1846 - val_acc: 0.0270\n",
      "Epoch 11/50\n",
      "1s - loss: 3.7890 - acc: 0.0449 - val_loss: 4.1931 - val_acc: 0.0233\n",
      "Epoch 12/50\n",
      "1s - loss: 3.6958 - acc: 0.0542 - val_loss: 4.2101 - val_acc: 0.0200\n",
      "Epoch 13/50\n",
      "1s - loss: 3.6138 - acc: 0.0584 - val_loss: 4.1850 - val_acc: 0.0292\n",
      "Epoch 14/50\n",
      "1s - loss: 3.5440 - acc: 0.0574 - val_loss: 4.1664 - val_acc: 0.0352\n",
      "Epoch 15/50\n",
      "1s - loss: 3.4630 - acc: 0.0647 - val_loss: 4.1833 - val_acc: 0.0357\n",
      "Epoch 16/50\n",
      "1s - loss: 3.3978 - acc: 0.0659 - val_loss: 4.2483 - val_acc: 0.0270\n",
      "Epoch 17/50\n",
      "1s - loss: 3.3340 - acc: 0.0756 - val_loss: 4.2390 - val_acc: 0.0324\n",
      "Epoch 18/50\n",
      "1s - loss: 3.2754 - acc: 0.0726 - val_loss: 4.2974 - val_acc: 0.0395\n",
      "Epoch 19/50\n",
      "1s - loss: 3.2104 - acc: 0.0821 - val_loss: 4.3521 - val_acc: 0.0443\n",
      "Epoch 20/50\n",
      "1s - loss: 3.1415 - acc: 0.0933 - val_loss: 4.3960 - val_acc: 0.0368\n",
      "Epoch 21/50\n",
      "1s - loss: 3.0785 - acc: 0.0981 - val_loss: 4.4723 - val_acc: 0.0498\n",
      "Epoch 22/50\n",
      "1s - loss: 3.0216 - acc: 0.1051 - val_loss: 4.5131 - val_acc: 0.0498\n",
      "Epoch 23/50\n",
      "1s - loss: 2.9494 - acc: 0.1125 - val_loss: 4.5534 - val_acc: 0.0622\n",
      "Epoch 24/50\n",
      "1s - loss: 2.8595 - acc: 0.1388 - val_loss: 4.5630 - val_acc: 0.0736\n",
      "Epoch 25/50\n",
      "1s - loss: 2.7585 - acc: 0.1670 - val_loss: 4.4371 - val_acc: 0.0936\n",
      "Epoch 26/50\n",
      "1s - loss: 2.5935 - acc: 0.2125 - val_loss: 4.4993 - val_acc: 0.1341\n",
      "Epoch 27/50\n",
      "1s - loss: 2.3872 - acc: 0.2652 - val_loss: 4.2940 - val_acc: 0.1412\n",
      "Epoch 28/50\n",
      "1s - loss: 2.1585 - acc: 0.3257 - val_loss: 4.1227 - val_acc: 0.1828\n",
      "Epoch 29/50\n",
      "1s - loss: 1.9294 - acc: 0.3805 - val_loss: 4.0490 - val_acc: 0.2396\n",
      "Epoch 30/50\n",
      "1s - loss: 1.7203 - acc: 0.4565 - val_loss: 3.8892 - val_acc: 0.2720\n",
      "Epoch 31/50\n",
      "1s - loss: 1.5050 - acc: 0.5316 - val_loss: 3.8345 - val_acc: 0.3029\n",
      "Epoch 32/50\n",
      "1s - loss: 1.3144 - acc: 0.6034 - val_loss: 3.8281 - val_acc: 0.3580\n",
      "Epoch 33/50\n",
      "1s - loss: 1.1422 - acc: 0.6713 - val_loss: 3.6777 - val_acc: 0.3948\n",
      "Epoch 34/50\n",
      "1s - loss: 0.9732 - acc: 0.7308 - val_loss: 3.6564 - val_acc: 0.4164\n",
      "Epoch 35/50\n",
      "1s - loss: 0.8048 - acc: 0.7957 - val_loss: 3.5744 - val_acc: 0.4359\n",
      "Epoch 36/50\n",
      "1s - loss: 0.6817 - acc: 0.8384 - val_loss: 3.6597 - val_acc: 0.4397\n",
      "Epoch 37/50\n",
      "1s - loss: 0.5659 - acc: 0.8716 - val_loss: 3.5844 - val_acc: 0.4435\n",
      "Epoch 38/50\n",
      "1s - loss: 0.4910 - acc: 0.8910 - val_loss: 3.6984 - val_acc: 0.4435\n",
      "Epoch 39/50\n",
      "1s - loss: 0.4135 - acc: 0.9132 - val_loss: 3.6609 - val_acc: 0.4413\n",
      "Epoch 40/50\n",
      "1s - loss: 0.3709 - acc: 0.9209 - val_loss: 3.8204 - val_acc: 0.4446\n",
      "Epoch 41/50\n",
      "1s - loss: 0.3325 - acc: 0.9312 - val_loss: 3.8278 - val_acc: 0.4456\n",
      "Epoch 42/50\n",
      "1s - loss: 0.2961 - acc: 0.9401 - val_loss: 3.9336 - val_acc: 0.4467\n",
      "Epoch 43/50\n",
      "1s - loss: 0.2661 - acc: 0.9461 - val_loss: 4.0322 - val_acc: 0.4484\n",
      "Epoch 44/50\n",
      "1s - loss: 0.2399 - acc: 0.9535 - val_loss: 4.0442 - val_acc: 0.4473\n",
      "Epoch 45/50\n",
      "1s - loss: 0.2136 - acc: 0.9610 - val_loss: 4.2476 - val_acc: 0.4489\n",
      "Epoch 46/50\n",
      "1s - loss: 0.2034 - acc: 0.9595 - val_loss: 4.3404 - val_acc: 0.4473\n",
      "Epoch 47/50\n",
      "1s - loss: 0.1855 - acc: 0.9643 - val_loss: 4.3087 - val_acc: 0.4467\n",
      "Epoch 48/50\n",
      "1s - loss: 0.1762 - acc: 0.9667 - val_loss: 4.4068 - val_acc: 0.4462\n",
      "Epoch 49/50\n",
      "1s - loss: 0.1640 - acc: 0.9705 - val_loss: 4.6885 - val_acc: 0.4484\n",
      "Epoch 50/50\n",
      "1s - loss: 0.1618 - acc: 0.9695 - val_loss: 4.5232 - val_acc: 0.4489\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=training_epochs,\n",
    "                    verbose=2, # This is for what we want it to display out as it trains \n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_train(hist):\n",
    "    h = hist.history\n",
    "    if 'acc' in h:\n",
    "        meas='acc'\n",
    "        loc='lower right'\n",
    "    else:\n",
    "        meas='loss'\n",
    "        loc='upper right'\n",
    "    plt.plot(hist.history[meas])\n",
    "    plt.plot(hist.history['val_'+meas])\n",
    "    plt.title('model '+meas)\n",
    "    plt.ylabel(meas)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc=loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c2f80f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_train(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 8 0 7 5\n"
     ]
    }
   ],
   "source": [
    "indx = 44\n",
    "\n",
    "print(np.argmax(x_test[indx,0:1]),\n",
    "      np.argmax(x_test[indx,2:11]),\n",
    "      np.argmax(x_test[indx,12:21]),\n",
    "      np.argmax(x_test[indx,22:23]),\n",
    "      np.argmax(x_test[indx,24:33]),\n",
    "      np.argmax(x_test[indx,34:43]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n"
     ]
    }
   ],
   "source": [
    "for result in model.predict(x_test[indx:indx+1]):\n",
    "    print(np.argmax(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.163247558066\n",
      "Test accuracy: 0.96548223326\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_test = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         0\n",
      "          1       1.00      1.00      1.00         2\n",
      "          2       1.00      1.00      1.00         2\n",
      "          3       1.00      1.00      1.00         2\n",
      "          4       1.00      1.00      1.00         2\n",
      "          5       1.00      1.00      1.00         2\n",
      "          6       1.00      1.00      1.00         2\n",
      "          7       1.00      0.25      0.40         4\n",
      "          8       1.00      1.00      1.00         4\n",
      "          9       1.00      1.00      1.00         4\n",
      "         10       1.00      1.00      1.00         4\n",
      "         11       1.00      1.00      1.00         4\n",
      "         12       1.00      1.00      1.00         4\n",
      "         13       1.00      1.00      1.00         4\n",
      "         14       1.00      1.00      1.00         4\n",
      "         15       1.00      1.00      1.00         4\n",
      "         16       1.00      1.00      1.00         4\n",
      "         17       1.00      1.00      1.00         4\n",
      "         18       1.00      1.00      1.00         4\n",
      "         19       0.67      1.00      0.80         4\n",
      "         20       1.00      1.00      1.00         4\n",
      "         21       1.00      1.00      1.00         4\n",
      "         22       1.00      1.00      1.00         4\n",
      "         23       1.00      1.00      1.00         4\n",
      "         24       1.00      0.67      0.80         6\n",
      "         25       1.00      0.83      0.91         6\n",
      "         26       1.00      1.00      1.00         6\n",
      "         27       1.00      1.00      1.00         6\n",
      "         28       1.00      1.00      1.00         5\n",
      "         29       1.00      0.67      0.80         6\n",
      "         30       1.00      1.00      1.00         6\n",
      "         31       1.00      1.00      1.00         6\n",
      "         32       1.00      1.00      1.00         6\n",
      "         33       1.00      1.00      1.00         6\n",
      "         34       0.67      1.00      0.80         4\n",
      "         35       0.86      1.00      0.92         6\n",
      "         36       1.00      1.00      1.00         6\n",
      "         37       1.00      1.00      1.00         6\n",
      "         38       1.00      1.00      1.00         6\n",
      "         39       1.00      1.00      1.00         6\n",
      "         40       1.00      1.00      1.00         5\n",
      "         41       1.00      1.00      1.00         6\n",
      "         42       1.00      1.00      1.00         6\n",
      "         43       1.00      1.00      1.00         6\n",
      "         44       1.00      0.75      0.86         8\n",
      "         45       1.00      1.00      1.00         8\n",
      "         46       1.00      0.88      0.93         8\n",
      "         47       0.00      0.00      0.00         8\n",
      "         48       1.00      1.00      1.00         8\n",
      "         49       1.00      1.00      1.00        10\n",
      "         50       1.00      1.00      1.00        10\n",
      "         51       1.00      1.00      1.00         8\n",
      "         52       1.00      1.00      1.00        10\n",
      "         53       1.00      1.00      1.00        10\n",
      "         54       0.83      1.00      0.91        10\n",
      "         55       1.00      1.00      1.00        10\n",
      "         56       0.91      1.00      0.95        10\n",
      "         57       0.50      1.00      0.67         8\n",
      "         58       1.00      1.00      1.00        10\n",
      "         59       1.00      1.00      1.00        10\n",
      "         60       1.00      1.00      1.00        10\n",
      "         61       1.00      1.00      1.00        10\n",
      "         62       1.00      1.00      1.00        10\n",
      "         63       1.00      1.00      1.00        10\n",
      "         64       1.00      1.00      1.00        10\n",
      "         65       1.00      1.00      1.00        10\n",
      "         66       1.00      1.00      1.00        10\n",
      "         67       1.00      1.00      1.00        10\n",
      "         68       1.00      1.00      1.00        10\n",
      "         69       1.00      1.00      1.00        10\n",
      "         70       1.00      1.00      1.00        10\n",
      "         71       1.00      1.00      1.00         8\n",
      "         72       1.00      1.00      1.00        10\n",
      "         73       1.00      1.00      1.00        10\n",
      "         74       1.00      1.00      1.00         9\n",
      "         75       1.00      1.00      1.00        10\n",
      "         76       1.00      1.00      1.00         8\n",
      "         77       1.00      1.00      1.00         8\n",
      "         78       1.00      1.00      1.00        10\n",
      "         79       1.00      1.00      1.00        10\n",
      "         80       1.00      1.00      1.00        10\n",
      "         81       1.00      1.00      1.00        10\n",
      "         82       1.00      1.00      1.00         8\n",
      "         83       1.00      1.00      1.00        10\n",
      "         84       1.00      1.00      1.00        10\n",
      "         85       1.00      1.00      1.00        10\n",
      "         86       1.00      1.00      1.00        10\n",
      "         87       1.00      1.00      1.00        10\n",
      "         88       1.00      1.00      1.00        10\n",
      "         89       1.00      1.00      1.00        10\n",
      "         90       1.00      1.00      1.00        10\n",
      "         91       0.83      1.00      0.91        10\n",
      "         92       1.00      1.00      1.00        10\n",
      "         93       1.00      1.00      1.00        10\n",
      "         94       1.00      1.00      1.00         8\n",
      "         95       1.00      1.00      1.00        10\n",
      "         96       1.00      1.00      1.00        10\n",
      "         97       1.00      1.00      1.00        10\n",
      "         98       1.00      1.00      1.00        10\n",
      "         99       1.00      1.00      1.00         8\n",
      "        100       1.00      1.00      1.00        10\n",
      "        101       1.00      0.80      0.89        10\n",
      "        102       1.00      1.00      1.00         8\n",
      "        103       1.00      1.00      1.00         8\n",
      "        104       1.00      0.75      0.86         8\n",
      "        105       1.00      0.88      0.93         8\n",
      "        106       1.00      1.00      1.00         8\n",
      "        107       1.00      1.00      1.00         8\n",
      "        108       1.00      1.00      1.00         6\n",
      "        109       1.00      1.00      1.00         6\n",
      "        110       1.00      1.00      1.00         6\n",
      "        111       1.00      1.00      1.00         6\n",
      "        112       1.00      1.00      1.00         6\n",
      "        113       1.00      1.00      1.00         6\n",
      "        114       0.71      1.00      0.83         5\n",
      "        115       0.80      0.67      0.73         6\n",
      "        116       1.00      0.67      0.80         6\n",
      "        117       1.00      1.00      1.00         6\n",
      "        118       1.00      1.00      1.00         6\n",
      "        119       1.00      1.00      1.00         4\n",
      "        120       1.00      1.00      1.00         6\n",
      "        121       1.00      1.00      1.00         6\n",
      "        122       1.00      1.00      1.00         6\n",
      "        123       1.00      1.00      1.00         6\n",
      "        124       1.00      0.60      0.75         5\n",
      "        125       0.67      1.00      0.80         4\n",
      "        126       0.67      1.00      0.80         4\n",
      "        127       1.00      1.00      1.00         4\n",
      "        128       1.00      1.00      1.00         4\n",
      "        129       1.00      1.00      1.00         4\n",
      "        130       1.00      1.00      1.00         4\n",
      "        131       1.00      1.00      1.00         4\n",
      "        132       1.00      1.00      1.00         4\n",
      "        133       1.00      1.00      1.00         4\n",
      "        134       0.50      1.00      0.67         4\n",
      "        135       1.00      1.00      1.00         4\n",
      "        136       1.00      1.00      1.00         4\n",
      "        137       1.00      1.00      1.00         4\n",
      "        138       1.00      1.00      1.00         4\n",
      "        139       0.67      1.00      0.80         4\n",
      "        140       1.00      1.00      1.00         4\n",
      "        141       1.00      1.00      1.00         4\n",
      "        142       1.00      1.00      1.00         4\n",
      "        143       1.00      1.00      1.00         4\n",
      "        144       1.00      0.50      0.67         4\n",
      "        145       1.00      1.00      1.00         2\n",
      "        146       1.00      1.00      1.00         2\n",
      "        147       1.00      1.00      1.00         2\n",
      "        148       1.00      1.00      1.00         2\n",
      "        149       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.97      0.97      0.96       985\n",
      "\n",
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 2 0 ..., 0 0 0]\n",
      " [0 0 2 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 2 0 0]\n",
      " [0 0 0 ..., 0 2 0]\n",
      " [0 0 0 ..., 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ianlo/anaconda/envs/tensorflow13_py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 150, does not match size of target_names, 200\n",
      "  .format(len(labels), len(target_names))\n",
      "/Users/ianlo/anaconda/envs/tensorflow13_py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/ianlo/anaconda/envs/tensorflow13_py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "target_names = [str(cls) for cls in range(0,y_train.shape[1]-1)]\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASkAAAD3CAYAAABB2qJpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJztnXuUZXV15z/7VldV16OfVNPd0A1NQ9O8lEdjEJhREBVk\nxEcmRtBkOVHjmomjDCFxdJaZrExmMq6VWcZHXM4whpCIwSjK6EIDItouJUaE8Ozm0doC3UBDv4Cu\nru6q6nv3/LF/J/dWdT3OuefeU79za39qnVX33jq/c/Y9de6+v9/+7e9vi6riOI4TK5W5NsBxHGcm\n3Ek5jhM17qQcx4kad1KO40SNOynHcaLGnZTjOFHjTspxnLYgIjeKyIsi8mjDa8tF5C4R2RZ+L5vt\nOO6kHMdpFzcBV0x67ePA3aq6Abg7PJ8R8WROx3HahYisA25X1bPC8yeAS1T1eRFZDWxW1Y0zHWNB\nTgPOA34d6Af+SFUPTrfvYP+gLl96DC89f4ClqxdlOk+sbWK1K+Y2Mdg1sKR/6tcHBjh4cNpbeM7a\npN3/8ccf36OqKzIZM4nLLx3Qvfuqqfa9/+HRLcDhhpduUNUbZmm2UlWfD493AStnO08uJwVcA9wI\nfBr4JPCJxj+KyIeADwEMDQ3x6c99hv1P72fZmiWZTrJ/58tRtonVrpjbxGDXwoHeKV8fHBxkeHg4\n03mKaJN2/6uuuurpTIZMwd59Ve6984RU+3at3nZYVc9v9lyqqiIy61Aur5M6Hng7sARYOOve1Rq6\naOpvMcdx5h4FatTaeYoXRGR1w3Dvxdka5A2c3wa8ATg1zckA5MAIdHm83nFiRFHGtZpqa5JvA+8L\nj98HfGu2Brm8hap+PTwcBE4XkRNTNazW3FE5TqTUUv7MhojcAvwU2CgiO0XkA8CngDeJyDbgjeH5\njOQNnP8NcA6wD7hZVdOPiRsdVbWt3UvHcVKiKNUWzfir6jXT/OmyLMfJG5M6CegCFgF9OY/lOE4E\n1IgrLSmvk9oB7AEux4Ln2Uh6UF0V7005TgQoUO0wJ7UO6AaqpMh3mJZqDSoCtbgujuPMRzqtJ/W3\nWFr7PixqP4GQ2HUDwLq163T/zpf52h/+A7/552+Z8mBjqwbp2XV0PshMbaajiDax2hVzmxjs2rBp\n/ZSvX3LJJWzevDnTeYpo08w5mkWB8chUKLlkMSLyBeC1wFPA36nqNyb9vTGZc9MX//J/z5qYp90V\nZHzi0C+GBMC5OkentYnBrg5O5rw/T3IlwKvP7tbvfHco1b4nrNmV+3xpyJwHICKnishNIvIO4NeA\nA8D5wKxq5lTHH6+h3Z6e4DhzgkI15VYUzXqDVcAFwPPAEPAcaTLOU+KOynHmBss4T7cVRbMxqeXA\nBmAAOAKsBX7eKqOg7qgmD/0cx2knQhWZayMm0Ex3ZQg4EdgE3AMItgrCYy20C/AeleMUjQXOJdVW\nFHk9wN3AGqCH/DOFUyLjNcZWDbbj0I7jTMLypCTVVhR5ndSfAy8Bw7QocD4VPbuGvUflOAVRU0m1\nFUXe3s8STBKzCJh6XrdFeIzKcdpP0pOKibzdk2eBH4fHbX9niaPyXpXjtAdFqFJJtRVF3jOtB44h\nryzGcZxo6LTh3lPAq4Bx4N7c1qQgGe750M9xWo8ijGnXXJsxgWac1ApgBFgMnAD8EutNvRn4ZuOO\nWbV70zFdm+m0fjO1aeY8rdrf28Rhl2v3pseSOeMKp2TW7onIKuCLWA+qC3gEeA3wB6r6lUn7Ztbu\nTcVMbabrUc0XHVrZ2sRgl2v3pmfjqxfqF7+dboHdy056shDtXjM9qQuAM7Fs8y3YwncPhseF47N+\njtM6VIWqxtWTasaaswmJqcDu8Np65shJgWemO04rqSGptqJopif1Q+B0rEeVxKA2YcsHj7fIrsx4\nj8px8mOB87aIR5qmGWsuBV6PJW8uxgLmvU0eq6VkdlS+bLHjTCDGwHlex3IdJosZwGQx+3JblBMZ\nr1HrSXmRfdlixzmKaoE5UGnI66SSKjFtl8VkoTJWY3R9P4yl2NkdlOP8C0nGeUzkteYgBcpistC7\nfQTtjetiO04ZqGkl1VYUeXtSy5goi5mzGb6pkNH60K8y5rEnx5kNExjH9eWe10ntpmBZjOM47UMR\nxiOTxTTjMoepL4W8EpPF7MNm+Yqla3bzK2M1KmOeR+U4aVCFqlZSbUXRbE+qDysKugtb33wBc1Fm\nPUP6gIzX0N4KMurDPseZnmITNdPQrJM6hOn2FHgBK8zwxOSd2i0wbqbN6Pp+erePtOQ8c/1eytgm\nBrtcYDw9CtHJYpoRGF8BvA9L6kyExmcAr1HVg5P2bbvAuJk20/WoyiiWLVubGOxygfH0nHjWIv3P\n30h3iA+ftjlagfEJwCBwGMuNuiA87sNSEqJHRn3o5zhToRS7oF0amh3uHY+lH/RgdfeWU2y9wNzI\nqGv9HGcyVtJqzhVuE2hm8HkPsBVb+O4UTHC8q8ljzSlJMN1xnIR05ayKLNbQjMu8GItBLQbOx3pT\ni4BjgT2tM60YfOjnOHUUCs0mT0Nea/YSqSwmC4mjchyn84qDDtEh1WJkNIiSHWceoyot1e6JyHUi\nskVEHhWRW0RkYVabWtGT6hhZjIuSnfmOBc67Um2zISLHAx8FzlfVs7Dcyquz2tRMTGolFn8aDb93\nAM8xRbWYMuKiZGd+0/I1zhcAfSIyDvRjviLzAVIjIudiQfM+LOt8HMuVOhNzVo7jlBgLnKeONw2J\nyH0Nz28IKhM7luqzIvK/gGcwf/E9Vf1eVpuy9qTeD5yKzewBPA5sAL6pqj/PevJYSXpQPuvnzEcy\nLNWyZ6aMcxFZBrwdqyj1EvB1EfktVb05iz3N9Ov2YjN5f40FzgeB/9rEcaLHZ/2c+UaScd6iMutv\nBH6lqrtVdRwLB12U1aY8qaU/Bn4Hy5Oa8jgxCoybaTOdKHmu7SpjmxjscoHxzLSwEMMzwGtFpB8b\n7l0G3Ddzk6PJJDAWkc9jRRfeBdwJLMWWarlSVX85xf5RCoybaTPV0G/a/WeoQhPDe5nLNjHY5QLj\n6Vl5xnK9+iuXp9r3c+d9ddbzicifAO/G5HMPAB9U1dEsNmXtST0PrAvtLgQOYLN90RRhaBcyWqPS\np9QOpejmepksp6TYcK91IQ5V/WPgj/McI6s1/4AtGTyGDeOeBnar6tY8RpSF2iGBhRkybSulTcJ3\n5jFlzzh/P/AaLA71Rmwp4eUicmarDYuWwxnW36oplT4vmeWUhyQFoUWB85bQbOC8G1iPyWF6ibBS\nTLtJ63xSDQ8dJxpaO9xrBXms+RUdJInJSu2QsOHsqZchdpwyUwvrnM+2FUUzTqqCLXB3POacXgS+\nLCLzrsuw7aF+FvZ7kNzpHFRhvNaVaiuKrE7qeaznZDUErSd1PLbo3dmtNa0cHB6pUOnz2JPTGbQ4\nmbMlZHJSqvpnwD8B+7EZvoVY3b3zyV9o1HGcCOiE4d46zEENAd8Jr50MPNkim0pH7ZBQOyQ+9HNK\nT4yze3nD+PcCa5hBGjOfODxScUfllJ5WLnrXCvI6lg9j6uYBrHrMvtwWlZzEUR0eiWsa13HSoCoc\niSwFIa+TWokF0BcxhTSmUwTGzey/4ewRtj109HLEsb6XotrEYJcLjGcmtrp7zVQwvh64Ehvmbcek\nMh8F3qyq2yft2zEC42b2n6pHFet7KapNDHa5wHh6lp52rL7+S7+Zat9v/+svRFvBuA/rNSlwSXht\nBbYawvZp2sxLkvQEzzp3ykRsPalmBp8nY6XWe4GbMac1BmxroV0dg8/6OWUixjypZnpST2HJmwDH\nYT2o/ViipzMFHkx3ykSROVBpyFqI4SRs+c9lWOWH47Cqxc8B76QDqsW0C09PcMqAKhypxfVlmtWa\nj2GrcY6Htj14tZjUHB6puCjZiZ7YhntZndRFWAxqAFgCPBoe39ZJ1WLaiYuSnZjphJhUX9i6gDuw\nIHrHVotpF41DP49TObGhHTC7l/A4LolxnI4jNoFxHudyDS6JaZqkB+Wzfk5MqMaXJ5XHSQ1htbSm\nlMQ46fD0BCcuhGrJZ/ca2YEVCAUiS6woGZ6e4MSEqqTaiiJPT+p0bOngKtMUYpjPAuNm2swHUXIM\ndrnAeHqS9aRiImsF4y3AK1gcahewAcuZOk9Vj1JAzneBcTNtOl2UHINdLjCenoENq/WMz/1Oqn3v\nu/J/FiIwzjrc20Y9/lTFHNV2bLVOpwX40M+Za2Kb3cvqpPZhlWL6gX+FOalXAx+fj9Vi2oU7Kmeu\n0BA4T7MVRdYzvQJ8Hrgbc1YnYD2qvczTajHtIlnmxXGKRjXdVhRZndRNwOXAxeH5Yqx3dRGe0Nly\nfJkXZy6IbXYva0mrB4H/g5VZPwJ8MfxpXleLaScuSnaKxHpJJXZSU/AALo1pO9se6qe7z3tUTjGU\nXWA8mf+BS2MKYfyQi5KdYigy3pSGvE5qGSaLcWmM43QAilDrIFkM2KqcLo0piMMjFZ/1c9qOptyK\nIq+TOg44hro0ximA2iFxR+W0hxYHzkVkqYjcKiKPi8hjInJhVpPyDveeAC7ApDH35jyWk4EkPcHj\nU07Lae3332eBO1T1N0SkB0sEz0RmJ6WqPxKRZzCJzHLgVqxizJuZVIjBBcbtb1M2UXIMdrnAeGZa\nlV4gIkuA1wH/zo6rY1j5u2zHySgwvgq4EPht4NuYJGY1ln3+3snrnLvAuJg2ZRIlx2CXC4ynp/fk\n43XNn/1eqn23X/3Jp7G4dMINoWMCgIicg3VStmKKlPuBa1X1YBabsvakzgauwNY1X445pyeBx70Q\nw9zhC+c5LUOB9D2pPbM4xQXAecBHVPVnIvJZ4OPAH2UxKetdfUH4/QrWjXsRK7H+dxmP47QYn/Vz\nWkULtXs7gZ2q+rPw/FbMaWUiq5NaHbZlwE+BU3FJTDS41s9pCS3KQVDVXcAOEdkYXroMG/plIs/s\n3g7gUlwSExW+zIuTj5br8j4CfCXM7G0H0q2o10Ae53IVLomJkkSUvGdvtmCz4wAtTUEIixLkCubn\ncVLHYPlRLomJkG0P9bP6VNf6ORlR0Fpc4pE8d+8+XBLjOB2IpNyKIY+TOh6XxERNovXzGJWTicjE\ne3mc1DbgVbgkJnrcUTmZKLmTUiyBU7FY1C+xYd+bW2yX02LcUTmpSJI502wFkTVwfizmmE4Lj3vD\nMfqm2tm1e/G1mU7rV5Rtc/3+wbV7sxHbondZtXubsbXNT8N6YT8ClgKfCFONk/d37V6EbaaT0MyX\na+bavenpXbdGV33y2lT7PvO7H4uyOOj3sTXNuzAHdRawnilKrDvx4kM/ZyZE021FkdVJXYplmh/C\ndDnjWCLn6hbb5bQZd1TOlKQNmhfopLLGpJK7ugdzUNWw7WylUU4xJKLk2iFPc3MSig2KpyFrT2oA\nOBGb2XsXtlyLACe12C6nIFyU7BxFyXtSjRyDBdFdFlNyfOjnTCCyWyFPMqfgspiOwSslO0CUeVJ5\nnNQALovpKLY91M/C/pr3quY5sc3u5RnubcFlMY7TeUSWzDlrT0pEThWRm0TkHdiwLgmbnQg8DOwC\n/m9brXQKwwuQOrGRdri3ClvfvEZdu7cF2Ig5q0MisrQtFjpzgs/6zV/KOtxbDmzA6us9iklh7gKG\ngIPAmW2xzmkPXRWozu6API9qHqJAZIvepXFSQ1hvaQV1QXEFq158O/A2YJ2qvjS5oQuMO6NN/xnK\nyNapb9wyXjMXGM9CZCP9WQXGIrIK+DqWD7UUczrvAj4FPAV8F3gWOFdVq5PausC4Q9pM16Mq4zVz\ngfH09K5dq2uuuy7Vvtuvvz4agfF64ITweA9wCeawnsAqGW/B0hF8Ie0OpnZI0N4M/+Iuvx1KS2QZ\n53nvpNdjWecVVR1vgT1OxMhoDRamjFdUa1CJK7bhpKSETmoP8ALwC2y49yNgGJvZq2CL3y0UkRXt\nMtKJiMOaPj2hFllww5mVtDN7sc3uNQbO+7HeU7I0y37Mgf0brAafMw+oHRKf9etkSji7NxOnYHlT\n48BiYG9ui5xSkDlG5ZSGIntJacjrpF7AcqSGsV6VM4+Q0Rqj6/tRqVi8yukMInNSWb8Kq9jywYlD\nGsSSOytYHT7HccpMhDGprE7qaWAJlmX+BNANnIGvJzVv6d0+gozWfOjXSZRwdq+RO7Hg+SvAQ9hw\nbz9We+9Aa01zyoQ7qs5Baum2osh6Vz2P9Z4ES0fYjPnUgalkMc78wh2V0w7y3lG3YjGqioh0tcAe\np+S4o+oAIhvu5Z3d+3vgcSxoXsEC6/+CC4znb5vDawdYuONgdHaBC4xnpOCgeBqyCoyvBf4K2Aq8\nD7gPq8F3HLBRVXdPausC43ncRrsryHgt3f4zLB/jAuPiBMYLj1ur6z70+6n2feJPfj9KgfFp2NpS\nCf8B+DIWNPeYlDMBGa+h3SmHftWai5JjocOGe5/Hss0XucDYmQoZtxhVqmTPFAvxOe1FKHbmLg1Z\nBcYPYOkHP1HV/aH9d4DDInJM26x0So0H00tEi5M5RaRLRB4QkdubNSnNnZMIjDcB54bnV4rIMmAE\n+CDmgF0W40yLjGYY+jlzS2uHe9cCj+UxJ+tdsww4DKzDhooui3FSI+Om9XMip0VOSkTWYCukfCmP\nOc18tR3EpDH9uCzGyUjv9hG0t+LDv4jJMNwbEpH7GrYPTTrUZ4CPkbNwezOB8y7qzu0FzGEtwGUx\njtMZpB/K7ZkuBUFE3gq8qKr3i8gleczJ+nX2qvA7SdrcjMtinIzIaM2D6bGiLdPuXQy8TUSeAr4K\nvEFEbm7GJJfFOHOGO6pIaUFMSlU/oaprVHUdcDXwA1X9rWbMyXuHJLKYaguO5cxDZLSGLvAqNDFR\n9vWkJtODzeolNfkcJzNyJGNmutNeWpxxrqqbVfWtzZqTN+N8OzMUYnCBsbfJsv/YqkF6dh2tUXOB\ncbEC49iWD84qML4NK6veA1wB3AF8H3gnsElV905q6wJjb5Np/0yi5CbP4wLj6elfuVZPeU86gfEj\nn4lTYHwqsBJLQxjDlhB+K5Z57hnnTm4yiZKdttAJMak9WOZ5P5Zx3g28pKoeLHBagjuqOSayVRCy\nCoz/EniKes/pFGwlhJNFZG2bbHTmIe6o5pDInFTWCsbvxyoYCyaF6QE+jvWmHKeluKOaAyJcmbOZ\n2b1hLN1gOS6LcdqMjNcYWzU4ZUDdaROROalmqsW8hAXOR3FZjON0HGUvaTUZl8U4badn17AP/Qqk\nE2b3GnFZjFMY7qgKIG3QvEROymUxTqG4oyqADnNS24F7sBiVx6ScQnBH1T6E+IZ7ebV7p2Cr7o0D\ni4G9M+/uOK0hcVQ+49d6pBbX9F5eJ/UCcCaWlnCULMYFxt6m3edoRpTsAuMZ6ACB8V9gYuKLsOox\ntwL/CLwJeIuq7pjU1gXG3qbt58gqSnaB8fQMDK3VM952Xap97/vr66MUGINVi6lh/rYKXIYFz19u\nuXWOkwKPUbWYyALnWYd7Z2LymB4s/lTDhMb/iKcgOHOIx6haRxllMYnA+BmsR1XDdHvHYVKYUUzf\n5zhzijuqFhGZk8pawTip7NgTfj+KZZyvc1mMEwM+9MuJuizGcfKRohCDjNfQRf1etKEJYsyTclmM\n4zgTUU23FYTLYpxykbJajBwYsX29N5WZTutJuSzGiRt3VNmIUGDsshin80kcldfsS0WRQfE0tFUW\n4zjR4I4qNbE5qaz94PVYj6kang9iaQgVLDblOMWTdjjnDmp2lOgC52l6UtuBJ7Hg+F7gUNjAau/t\noZ43NYFGgfHGjRt1aOUx/Ma7/21msWSsbWK1K+Y2sdoFLjBOiC3jPI3A+CLgFmw49y0sBvUe4C3A\n3wKrsCKh752c0NkoMF6xYsWmG2+8MVoRZzNtYrUr5jax2hVzmyIFxoPL1uo5l16bat97bvvDQgTG\nWWNSb8K0ezVgJzbUOxYY8oxzxyk/STJnTGTV7o0CB7FyVmuAb2JxKo9HOU4noFrKRe8ai4M+H34v\nwQqCvgxcDIyISJeqVqc9iuM45SAuH+WyGMdxJhJbxnnePKnJspjduS1yHGfuUCCy4Z7LYhzHmUhk\nspi8TuoULEaVyGIcxyk5rRruichaEfmhiGwVkS0iki63YRIui3EcZwItnN07Alyvqv8sIouA+0Xk\nLlXdmuUgWXtSu7COXtLOZTGO00m0cBUEVX1eVf85PD4APEYTfiJrT2oNdd0eWBrCGeG34zglx5I5\nU/ekhkTkvobnNwQp3NHHFVkHnAv8LKtNWZ3UKdgMXg2bzXsBy5lagBVlmMBk7d7g4GC0+qhm2sRq\nV8xtYrUr5jZFa/dIr8Pek0YWIyKDwDeA/6Sqr2Q1J2tx0OOAB4B1wAeAkzEd30pVPWeKtq7d8zal\nsCvmNkVq9xYvXqOvOf/Dqfb9wQ//y6znE5Fu4HbgTlX9dDM2ZS0OugcrZyXh+SKsiswRL8TgOB1A\nC2NSIiLAXwGPNeugIHvgfBhYHdo9CJze8JrjOKXHtHtpthRcDPw28AYReTBsV2a1KKvA+LXAI9jy\nLBuxYd8twDuynthxnEhp0YJ2qvoT6qOupskqMO7HgudLgD4sWr8JG/Ytx2UxjlNutPzLB0/GZTGO\n02mUcPngmfBqMY7TacSlL3ZZjOM4E5FaXOO9rMO9CpZxvghYiMtiHKezUGxslGYriKxOaje2OmfS\nLpHF9LbSKMdx5gZBEU23FUVWJ3U7lnVeBR7Ghnv7gX1MIYtxHKeERBY4z+qkHsGGeQewggybsQ7i\ngFeLcZwOITInlTdwfivwe0xTiMEFxt6mLHbF3KZQgXESk4qIrALjtwNfAx5R1Q+KyJ1Y2sEFwGmq\nOj6prQuMvU0p7Iq5TZEC4yX9x+mFGz6Qat87H/7v0RQHTQTG+4HLsGKg54vIABY0fxlbtsULMThO\n6Sl2KJeGZoZ7L2KL3wHcgen4VFXdQTlO2VGic1JpAueJwPgXWE9pD3XndjowBqwJ68Y4jlN2IsuT\nyiow/i5wVsPfElnMAlwW4zgdQZE5UGlwWYzjOBOJzEllzZNaia0P8xLm4FwW4zidhCpUa+m2gsja\nkzoHm8VL8qG8WozjdBqR9aSyOqlTsUzzhVjQfMZqMY7jlJDInFTW4d4QcBgLkvfjshjH6SwUqGm6\nrSDyrsx5K5YzVfFqMY7TCShoLd1WEHln9/4eeBwLmidrTTmOU1aUQoPiacjrpHowB7WIKWQxLjD2\nNmWxK+Y2hVcwjiwmlVVgLJhW72Tg14GPYLXd/wA4xQXG3iaGc3Ram0IFxj0r9aJj351q3zue/XyU\nAuMubHYPYAB4HbAsbJ5x7jilp/wC4zHgNGxm70ngXqze3kE849xxyo8CJSzE0CgwHgd2YmkIa7AC\noeuAHaoFhvsdx2kfJVyZs1Fg3AUcweQwivWqdgCnichaVd3RLkMdxykCLf3s3gDwT8Ax2AoILotx\nnE5CIbZBUVYndRgb3vVgPSmXxThOp1FgNnkasmacD1Nfqv0QLotxnM4jspiUy2Icx6mjarN7abaC\nyOukEllMtQXHchwnBiLrSbVVFuM4TtlQtBqXBDdv72c7cA+WmuAxKccpOxEu1ZK3J5UUYhhnClmM\nC4y9TVnsirlN8QLjuFIQsgqMXwH2ARcC/x54D3A+1ovaNDnr3AXG3qYsdsXcpkiB8eLKMfraBZen\n2veu8VtmPZ+IXAF8FhttfUlVP5XVpjTDvURgDDa8OyU8fgJbRvgpTLc3mPXkjuNEhrZu0bsw4/8F\n4C1Y0vc1InJGVpPSOKkVWKLmCuDVwDPAKJZlfhbWuzob85SO45QcrVZTbSn4NeAXqrpdVceArwJv\nz2rPrDEpVf2WiLwM/C5wHPA9bGmWk4EHgLuxogwDzLASwu7du0evuuqqXZhgeSijnbG2idWumNvE\nalfMbdLuvzGjHUdxgP13fl9vTWvbQhG5r+H5DSEOnXA8pu1N2AlckNWmWZ1UiEl9AugFXsR6X09h\nQz+wId9WLBt9Ao2B8+TNqOr5k97YrMTaJla7Ym4Tq10xt8mw/54sdkxzrivyHqPVpJndex02Mfn/\nsJ7S8diQ7yHgW5iHv99lMY7jTOJZYG3D8zXhtUykGe59DfjaNH/+m6wndBxn3vBzYIOInIQ5p6ux\njIBM5M2TysIN0zxupn1MbWK1K+Y2sdoVc5tmzjGnqOoREfmPwJ3YxNqNqrol63FmzZNyHMeZS1wU\n7DhO1LiTchwnagqJSYnIecAHsczTLdiMYDewEguoKZbV3oVpAXsxPeBSTHIzDByL1f3bj1Wr6Q6/\nq6F9FzASXk8SS5OMsy5skb4F2OqifVhCai91R30kHKev4XEXNq37CpYjVgnnWEz92iXaRQm2Lg3n\n6Go4j4RzVcP+C8Ixu8NzaThnBctDSxYXrGBVerrCfjUsuXYwtD8cjl1reJ/doZ2GrRrOORp+j4d9\njoTnybGlwYYkpXg87FMJ+1XD1j3JxqRNcs4F4fiVcNxqw+vJ8+RvR8Lv5HkSg0jsbjxPcr2S54S/\nS8Nvwu+D4X9Aw9+7Ju2XXIPkf9h47yTXImmTPB/GUm+S60HDNWy0ZzrbJj9Ojpu870bbuhraJ//j\n5LqOY//7Mex/Oxr+vh9LEfqJqv43Sk5RPalrgI8CfwE8gn1Al2AXdBfwMPYBHwFuwi7yXViaww+D\nnfswh3EE+Gn42+HQ5hHgV8CPw/OD2M2zI5yrEn4fwP6hL2NLHyc3Q3ITJh+yajjX3nDcJeH1ceym\nH8GcAWHfveF4vwrH6Am2ScOxkw/gWNiq1J1XP3bTv4CtdjoabNwKPA38JNievK/N4Vxj1JdyHqV+\nsyb/18S5vBjO1R3e1+FwvBdD2+TDsDtsEq73cLhuh4HnwrGTXLnkPewO/7tR7AtnLPx/XsJKno03\n2H1fON54aLc/nGMrlhg8Hq5rNfw+Qt0pjoRj7g3XuNZwjZP3nVyHg+Fv9ze8Nh7aJNepFo6ftN0R\n9h2j7jjGqX951IIdR8Kxk2tQCf+3feG9jWD39N5wjR8Mxz8Q2h4K7Y80HHM87JPkGjZ+QTTuOxJe\nGw6/of5nox+zAAACuElEQVSFkfwfjmD3zstYsuVSSk6Rw73kW+IM7Ob8QTj/E5is5jbgZuBNmCNI\nvqFOxTJVf4ndkIPYt8RGzLkpJtmpYFnw+7EbJPkmPQJ8OTzfgX1w7g+Pt2M9u8PYjdYb9u8DVmO9\nonMxJ9KH9aD6sA90F3BLsDNxlsPAp8PjR4NNL1F3AEmvpYo5l2QZ5p5g8wgm2H4o/G0Au3lXBvue\no35TrsAc2Deof4j3h/d8EHMmYB/+pdTzUxYHGxZgNRMbeycD4bV94fXEATayKLzfMeo9moFwLfuZ\n2As7AfuwJB/qY8P1uxdz/ElvDKynepB6z3Nn+F9sxj6QY+H6DmNVs0ewfL3kC2BheLwwnKMX2BT+\n1hfei1D/cG8L12042Ngbfj9L3QkmvaiD1HuahPeZOBXBHNDiYPNwuB5Jz2gl9S8Ywe7jBdiXTLXh\nfY2E93uQuqNOevuHmNjL6mu4/smXXTc2QvkC1hNfQv0zVGoKmd0TkU3Ae4F3Yjf5A+FPq7B/zBDw\nHeAy7AInQ6OkdFayBMxi6t9qA9Q/4I3d+GTokAwda5iDWITdHNVw/C7qH4iku1/BbqLjsA/W0tD+\nx1gBioXhnKvC8ZIbcoz68CmxbxirqlMLfzsQ9k2cDOFYh8Jxu7EbdADL6F8Vjrs4HGNfsPnlcL36\ng60nhsfJMJLQDupDri6sbuKx4bVDwf5u7MOR9OgS5zUarivUh2XJllzj5Pi1htcbh2qNQzEaHicf\nrGRYJRztCBPnlwwFFzS0bTxm49BUqA/Dkv9pYmdiY3JfNB6/0ZbEuc42jGx0Ykm7JJTQ+L6SezLp\ngfU07Nt4XmXq65Vc+2Tf5N6pNeyb9OYOhuPfArwe+wJ/WFX/lJLjKQiO40SNz+45jhM17qQcx4ka\nd1KO40SNOynHcaLGnZTjOFHjTspxnKj5/4xB0KGFBKXzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12b85e940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "confmat=confusion_matrix(y_test, y_pred)\n",
    "ticks=np.linspace(0, 200,num=201)\n",
    "plt.imshow(confmat, interpolation='none')\n",
    "plt.colorbar()\n",
    "plt.xticks(ticks,fontsize=6)\n",
    "plt.yticks(ticks,fontsize=6)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
